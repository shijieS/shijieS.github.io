---
date: '2018-06-01 10:02 +0800'
published: true
comments: '1'
tags:
  - tracking
categories:
  - idear
layout: post
---
Data association and track-to-track association, two fundamental problems in single-sensor and multi-sensor multi-target tracking, are instances of an NP-hard combination optimization problem known as the multidimensional assignment problem (MDAP). 

Multi-target tracking with one or more sensors plays a significant role in many surveillance and robotics applications, A tracking algorithm provides higher-level systems with the ability to make real-time decisions based on an accurate picture of the surrounding environment. Within ITS, it can be used for pedestrian detection at intersections, self-driving cars, and for traffic surveillance. Multi-target tracking also has a myriad of other application ranging from general security systems to tracking cells in microscopy images. There are many different sensor modalities that can be used for these applications; the most common are video, radar, and LiDAR. As a motivating example, consider a vision system that tracks all traffic participants at an urban intersection. The real-time tracking data can be used for adaptive traffic signal control and optimize the flow of traffic at that intersection. However, urban traffic intersections contain numberous challenges for multi-target tracking. Heavy traffic occupying multiple lanes and unpredictable pedestrian motion makes for a cluttered scene with lots of occulusion, false alarms and missed detections. Variability in the appearance of the targets caused by poor lighting and weather conditions is especially problematic for visual tracking. On the other hand, new technologies such as vehicle-to-infrastructure communication enables vehicles to transmit information directly to traffic intersections, augmenting the data collected by traffic cameras and other sensors. However, tall buildings, trees, and other vehicles can increase GPS signal interference, a effects of multipath is still an ongoing area of research.

Prior to the proliferation of vision-based tracking, tracking methods primarily relies on kinematic data. A sensible intuition is that combining knematic information with the learned representations of high-dimensional sensor data will improve tracking performance. The aim of this survey is to review the algorithms used in data-driven multi-target tracking and discuss rectnltly proposed extensions. We believe that considering tracking from the perspective of an assignment problem is a good way to abstract away a lot of application-specific details and unify the many difference approaches.

The goal of data assignment is to identify a correspondence between a collection of new sensor measurements and preexisting tracks. New measurements can be generated by previously undetected targets, so care must be taken to not erroneously asign one of these measurements to a preexisting track. Likewise, the measurements that stem from clutter within the surveillance region must be identified to avioid false alarms. When there are multiple sensors, there is also the additional problem of track-to-track association. This problem seeks to find a correspondence between tracks of the same target that were generated by different sensors. In the track-to-track case, the problem becomes even harder as the sensors could produce vastly dfferent types of data. Note taht in this work, we use detections and measurements interchangeably; similarly, we equivocate targets with the term objects. We will attempt to be as consisitent as possible with our usage while also adhering to the norms of the different tracking communities when appropriate. For example, in vision-based tracking, the term detections is typically used instead of measurements.

Broadly speaking, algorithms for solving these two association tasks can be classified as either single-scan or multi-scan. A single-scan algorithm only uses track information from the most recent time step. whereas multi-scane algorithms use track information from multiple previous or future are closely spaced and there are a lot of false alarms and missed detections. Generally, multi-scan methods are preferable in situations where the objects of interest are closely spaced and there are a lot of false alarms and missed detections. However, delaying the association to leverage future information negatively affects the real-time capabilities of the tracker. The accuracy and precision of the tracks produced by multi-scan methods are usually superior and they offer fewer track ID switches, track breaks, and missed targets. Naturally, multi-scane methods are more computationally expensive and difficult to implement than their single-scan counterparts.


A common way to formualte these association tasks is as an assignment problem. The simples version is the 2D assignment problem, also known as bipartite matching or linear assignment (LAP), which seeks to match $$m$$ workers, e.g., tracks, to $$n$$ jobs, e.g., sensor measurements. This combinatorial optimization problem constrains the space of solution so that each trck is assigned to exactly one measurement, but measurements are allowed to not be assigned (i.e. false alarms) or to be assigned to a "dummy track" (i.e., a missed detection). The multidimensional extension to the assignment problem for track-to-track association stipulates that each track from each sensor be assigned exactly once. For multidimensional data association, constraints ensure that each sensor measurement at each time step is assigned to a track exactly once. Unfortuantely, the MDAP is NP-hard for dimensions $$\geq 3$$, whereas there exists many polynomial-time algorithms for the LAP. We will formuate these problems more rigorously.  The algorithm presented in this sruvey are for solving the various MDAPs encountered in multi-target tracking, and are generally applicable (with modification) to both data association and track-totrack association.

It has been suggested that non-kinematic data obtained from sensors can be incorporated into association algorithms to improve performance. For example, a classifier can be used to prevent two sensor tracks with different target class labels from being associated, which reduces the number of potential assignments. Appearance information has been used etensively in-depth survey. We will be discussing data-driven approaches for discovering features to augment association algorithms. Additionally, we will survey optimization algorithms for finding the solution to a MDAP.

There are several related surveys to ours, and we wish to highlight the relationship between the contributions of these surveys and those of our own. 


#### Problem formulation
We will first formally introduce the linear assignment problem (LAP) for single-sensor data association and track-to-track association with two sensors. Following this, we will examine the various MDAP formulations.

##### 2.1 Linear Assignment
Consider a scenario where there are $$m$$ existing tracks and $$n$$ new sensor measurements at time $$k, k=1,cdots, T$$. We assume that there is a matrix $$C_k \in \mathbb{R}^{m\times n}$$, withine entries $$c_k^{ij} \in C$$ representing the cost of assigning measurement $$j$$ to track $$i$$ at time $$k$$. The goal is to find the optimal assignment of measurements to tracks so that the total assignment coast is minimized. Using binary decision variable $$x^{ij} \in \{0, 1\}$$ to represent an assignment of a measurement to a track, we end up with a 0-1 interger program.

$$
min\limits_{x\in X} \sum\limits_{i=1}^m \sum\limits_{j=1}^n {c_k^{ij}x^{ij}}
$$

with constraints

$$
\left{ \begin{matrix}
\sum\limits_{i=1}^{m} x^{ij} =1, j = 1, \cdots, n \\
\sum\limits_{j=1}^n x^{ij} = 1, i = 1, \cdots, m
\end{matrix}\right.
$$

where $$x \in X $$ is a binary assignment matrix. There are $$mn$$ constraints forcing the rows and columns of $$X$$ to sum to 1. Note that $$C_k$$ is not required to be a square matrix. To capture the fact that some sensor measurements will either be false alarms or missed detections, a dummy track is added to the set of existing tracks, so that $$C_k$$ is now an $$(m+1)\times n $$ matrix. The entries in the $$(m+1)^{th}$$ row represents the costs of classifying measurements as false alarms. Missed detections are usually handled by forming validation gates around around the $$m$$ tracks. These gates can be used to determine, with some degree of confidence, whether any of the new measurements might have originated from a track. The canonical approach is use elliptical gates, which are typically computed from the convariance estimates provided by a Kalman Filter. In video-based tracking, a similar tactic is to suppress object detections with low confidence values.

Even though there are $$mn!$$ possible assignments, many polynomial-time algorithms exist for finding the globally optimal assignment matrix. Most famous is the $$O(n^3)$$ Hungarian, or Kuhan Munkres algorithm. Another popular method is the Auction algorithm, introduced by Bertsekas. These algorithms are fast and are easy to integrate into real-time multi-target tracking solutions. However, by only considering the previous times step when assigning measurements or tracks, we are making a Markovian assumption about the infomration needed to find the optimal assignment. In situations with lots of clutter, false alarms, missed detections and occlusion, the performance of these algorithms will significantly deteriorate. Indeed, it may be beneficial to instead use a sliding window of previous and ftuture track states to construct assignment cost that model the relationship between tracks and new sensor measurements more accurately. Instead of updating the assignment within the sliding window at each time step, and alternative approach is to simply delay making a decision within the sliding window. In the sequel, we describe how this affects the formulation of the assignment problem. The single-scan track track-to-track association problem with two sensor is also a LAP, where $$m$$ and $$n$$ represent the sets of tracks maintained by each sensor. Similar methods for handling false alarms and missed detections in data-association can be used for track-to-track association with uneven sensor track lists, i.e., $$m\neq n$$. If the assignment costs are known, an optimal track assignment can be found in polynomial-time using one of the previously mentioned algorithms.

##### 2.2 Multidimensional Assignment
Within the single-sensor and multi-sensor tracking paradigms, there are a few different ways to formulate data association and track-to-track association as a MDAP. Each formulation seeks to optimize slightly different criteria, but each solution technique is generally applicable to all of them with minor modifications.

We begin by considering the MDAP for multi-scan data association with one sensor. This scenario is the most commonly encountered, especially in video-based tracking. Let the number of scans or the temporal sliding window size, be given by $$T$$. Since the objective is to associate new sensor measurements with a set of existing tracks, the resulting MDAP has $$T+1$$-dimensions. When $$T \geq 2$$, the assignment problem is NP-hard.

Let the set of nosiy measurement at time $$k$$ be referred to as scan $$k$$ and be represented by $$Z_k=\{z_k^i\}$$, where $$i$$ is the $$i^{th}$$ measurement of scan $$k, i=1,\cdots, M_k$$. $$M_k$$ is the number of measurements in each scan, i.e., $$|Z_k|=M_k$$. The main assumption we are making is that each object is responsible for at most one measurement within each scan. We let $$Z^T=\{Z_1, \cdots, Z_T} represent all measurements in the sliding window of size $$T$$.

Let $$\mathbb{T}$$ be the set of all possible partitions of the set $$Z^T$$. We seek an optimal prtitioning $$\gamma^* \in \mathbb{T}$$, also called a hypothesis, of $$Z^T$$ into tracks. Note that a track is just an ordered set of measuremtns $$\{z_1^i, z_2^i, \cdots, z_T^i\}$$; one measurement from each scan at each time step is attributed to each track. Hence, a partition $$\gamma$$ represents a valid collection of tracks that adhere to the MDAP constraints. Now, we define $$\gamma^j$$ to be the $$j^{th}$$ track in $$\gamma$$. Following this, we can define a cost for each track $$\gamma^j$$ in a partition as $$c_{i_1, i_2, \cdots, i_T}$$, where the indices $$i_1, i_2, \cdots, i_T$$ indicate which measurements from each scan belong to this pariticular track. This represents the cost of track j being assigned measurement $$i$$ from scan 1, measurement $$i$$ from scan 2, and so on. Curcially, the multidimensional constraints prevent measurements from being assigned to two differenet tracks and ensure that each measurement is matched to a track. If we use binary variables $$\rho_{i_1, i_2, \cdots, i_T \in \{0, 1\}$$ to indicate if a track is present in a partition, then we can represent the MDAP objective as

$$
min\limits {\gamma\in \Gamma} \sum\limits_{i_1=1}^{M_1}\cdots \sum\limits_{i_T=1}^{M_T}c_{i_1, i_2, \cdots, i_T}\rho_{i_1, i_2, \cdots, i_T}
$$

with constraints

$$
\begin{matrix}
\sum\limits_{i_1=1}^{M_1}\cdots\sum\limits_{i_T=1}^{M_T}\rho_{i_1,i_2,\cdots, i_T} = 1; & i_1=1,\cdots, M_1 \\
\sum\limits_{i_1=1}^{M_1}\cdots\sum\limits_{i_T=1}^{M_T}\rho_{i_1,i_2,\cdots, i_T} = 1; & i_2=1,\cdots, M_2 \\
\vdots & \vdots \\
\sum\limits_{i_1=1}^{M_1}\cdots\sum\limits_{i_{T-1}=1}^{M_{T-1}}\rho_{i_1,i_2,\cdots, i_T} = 1; & i_2=1,\cdots, M_T
\end{matrix}
$$

The solution $$\rho$$ to this MDAP is the multidimensional extension of the binary assigment matrix. Simply, one may consider $$\rho$$ as being a multidimensional array with binary entries, such that the sum along each dimension is 1. Similarly to the LAP, we can augment each scan by including $$a z_k^0$$ dummy measurement in the set of detections at time $$k$$ to address false alarms. This is useful for identifying track birth and track death as well, but care should be taken wehn defining the cost for assigning measurements as false alarms or missed detections to avoid high number of alse positives and false negatives.

It is common to solve for an approximate solution within a fixed-sized sliding window $$T$$, then shift the sliding window forward in time by $$t < T$$ so that the new sliding window overlaps with the old region. This allows for tracks to be linked over times, and it provides a compromise between "offline" tracking, when $$T$$ is set to the length of an entire sequence of measurements, and "online" tracking, when $$T=1$$.

The other form of the MDAP we are interested in is multi-sensor association with $$S\geq 3$$ sensors. This scenario is common in centralizd tracking systems, where sensors that are distributed around a surveillance region report raw measurements to a central node. When each sensor sends its local tracks to a central node for track association and fusion. a MDAP must be solved. In this case, the dimensionality of the MDAP is equal to $$S$$, and hence, is NP-hard. The main difference between this problem and the previous data association problem is that it deals solely with tracks, as opposed to new sensor measurements from all sensors. Multi-scan track-to-track association with two sensors is also a MDAP, as wel as multi-scan multi-sensor data association, but we omit these cases for brevity in our formulation and for the fact that they canbe defined quite similarly from what is presented next.

In this scenario there are $$s\geq 3$$ sensors, each maintaining a set of local tracks and using a sliding window of size $$T \geq 1 $$. We define $$X_k^s = \{x_k^s\}, s=1,\cdots, S$$, to represent the set of track state estimates produced by sensor $$s$$ at time $$k$$. We have $$i=1, \cdots, N_s$$, where $$N_s$$ is the number of tracks being maintained by sensor $$s$$ and $$x_k^{i,s}$$ interpreted as the $$i^{th}$$ track of sensor $$s$$ at scan $$k$$. Then for each sebsirm we have $$x^{T,s}={X_1^s, \cdots, X_T^s$$, which represents the collection of track state estimates within the sliding window. We seek an optimal partitioning $$\gamma^*\in \Gamma $$ of $$X^T = \{X^{T,1}, \cdots, X^{T,S} \} $$ of tracks over all scans and sensors that minimizes the total assignment cost, and we can define a partial assignment hypothesis in a partition $$\gamma$$ as $$\gamma^l = \{\{x_1^{j,1}, x_1^{j,2}, \cdots, x_1^{j,N_s}, \cdots, \{x_T^{j,1}, x_T^{j,2}, \cdots, x_T^{j, N_s}\}\}$$. In other words, this states that the $$j^{th}$$ track of sensor 1 from scan 1, $$j^{th}$$ track of sensor 2 from scan 1, and so on.

#### Assignment costs
The assignment cost function has a massive impact on tracking performance. In this subsection, we will introduce various perspectives towards defining assignment costs, specifically highlighting probabilistic appraoches.

##### Kinematric Costs
In situations where sensor measurements only consist of noisy esitmates of kinematic data from targets (e.g., position and speed), a prbabilistic framework can be used to recover the unobservable state of the targets. The most common approach is to handle the uncertainty in the sensro measurements and target kinematics with a stochastic Bayesian recursive filter; The Kalman Filter-probably the most popular filter of this falvor-provides the means of updating a posterior distribution over the target state given by corresponding measurement likelihood, i.e., $$P(x_k|z_k) \propto P(z_k | z_{k-1})$$. We are using the same notation as befor, such taht $$ x_k $$ repressents the target state at time $$k$$ and $$z_k$$ is the measurement at time $$k$$. One of the reasons for the popularity of the Kalman Filter is that by assuming that all distributions of interest are Gaussian, the posterior update can be computed in closed form. Now recall that a partial association hypothesis $$gamma^j$$ for the multi-scan single-sensor data association problem assigns $$T$$ measurements to a single track within the sliding window of length $$T$$. The canonical cost function for data association is to minimize the following negative log-likelihood ratio:

$$
\begin{matrix}
c_{i_1, i_2, \cdots, i_T} = -log \frac{P(\gamma^j|z_1^i, z_2^i, \cdots, z_T^i)}{\gamma^0|z_1^i, z_2^i, \cdots, z_T^i} &, (\gamma^j, \gamma^0)\in \gamma.
\end{matrix}
$$

The partial hypothesis $$\gamma^j$$ represents the $$j^{th}$$ track of the hypothesis $$\gamma$$, and $$\gamma^0$$ represents a dummy track where all measurements attributed to it are considered false alarms. Assuming the sensor has a probability of 1 of detecting each target and a uniform prior over all assignment hypotheses, the likelihood that the $$j^{th}$$ track generated the assigned measurements is 

$$
P(\gamma^j|z_1^i, z_2^i, \cdots, z_T^i) \in P(z_1^i, z_2^i, \cdots, z_T^i | \gamma^j).
$$

Assuming independence of the measurements and trck states between time steps, we can decompose the likelihood that the measurements orginated from track $$\gamma^j$$ as 

$$
P(z_1^i, z_2^i, \cdots, z_T^i | \gamma^j) = \prod\limits_{k=1}^T P(z_k^i|x_k)P(x_k|j)
$$

In the Kalman Filter and its extensions, the right-hand side has an attractive closed form representation as a Mahalanobis distance between the measurement prediction and the observed masurements, scaled in each dimension of the measurement space by the state and measurement convairance. This can easily be derived by tracking and plugging it into the negative log-likelihood ratio.


In track-to-track association, the conventional cost function associated with a partial hypothesis is the likelihood that the tracks from multiple sensors were all generated by the same "true" target. When $$S=2$$, the simplest appraoch is to consider the random variable $$\Delta_{12}=x^1-x^2$$, which is the difference between the track state estimate from sensor 1 and sensor 2. When track state estimates are Gaussian random variable, $$\Delta_{12}$$ is also Gaussian. The cost fuction becomes the likelihood that $$\Delta_{12}$$ has zero mean and convariance given by $$\sum = \sum_1 + \sum_2 - \sum_{12} - \sum_{21}$$. The first two terms of the covariance are the uncertainty around the track state estimates, and the second two terms are the corss convariances. A straightforward way to extend to the $$S\geq 3$$ case is to use star-shaped costs $$\Delta_{1S}=\sum_{i=2}^S\Delta_{1i}$$. For the Gaussian case, the cost can also be writeen in closed form as a Mahalanobis distance between the track state estimates:

$$
c_{i_1, i_2, \cdots, i_S} = \sum\limits_{j=2}^S \Delta_{1j}^T\sum_{1j}^{-1}\Delta_{1j}
$$

##### Feature-augmented Costs
It is often the case in multiple target trcking that sensor generate high-dimensional observation of the surveillance region from which target information must be extracted. The most obvious example of this i the image data generated by a video surveillance system. Tis data, when featurized, can used to augment or replace the kinematic costs metioned in the previous subsection. The goal of doing this is to improve the association accuracy, and ultimately the overall tracking performance.

Due to the high-dimensonality of the raw measurements, almost all such methods attempt to learn a pairwise cost between measurements or tracks using feature extracted from the data. This pairwise cost can represent the association probability of the two objects, or simply some notation of siilarity, e.g., a distance. There are many ways of formulating the problem of learning assignment costs and using ti for solving data association or track-to-track association as a machine learning problme. For example, one technique is to use metric learning to transform the high dimensonal sensor measurements into a lower-dimensonal geometric space where a Euclidean distance can be used as the assignment cost function. Learning pairwise costs from data is heavily used in the multi-target tracking computer vision community, partially due to the ease at which features can be extracted from images.

There are multiple ways to incorporte learned pairwise cost into a MDAP solver. One common approach is as follows. The probability of association for a pair of measurements or tracks $$\Lambda_i$$ and $$\Lambda_j$$ can be written as a joint pdf; assuming independece of the kinematic ($$K$$) and non-kenematic ($$NK$$) components of tis probabilistic cost function, the resulting negative log-likelihood pariwise cost is:

$$
c_{ij} \begin{matrix}
=& -log P(\Lambda_i, \Lambda_j) \\
=& -log(P_K(\Lmabda_i, \Lambda_j) P_{NK}(\Lambda_i, \Lambda_j)\\
=& -log P_K(\Lmabda_i, \Lambda_j) - P_{NK}(\Lmabda_i, \Lambda_j)
\end{matrix}
$$

Usually, $$P_{NK}(\Lambda_i, \Lambda_j)$$ is parameterized by weights $$\theta$$ and is a function of the features exracted from the sensor data and $$\theta$$. For example, this prbability could be represented as a neural network that outputs a similarity score between 0 and 1. 

#### Optimization
In this section, we wil review recent work on a variety of optimization algorithms for solving MDAPs in real-time multi-target tracking systems. Our focus will be on approaches with a machine learning flavour, e.g., approximate inference techniques and deep neural networks, as well as the probabilistic modeling aspects of the problem. We will start by briefly convering non-probabilistic methods that are useful for constracting with whtat is currently popular. The techniques discussed in this section are quite general, and in most cases can be used for both the data association and track-to-track association problems with proper modification. It is important to notice that certain modeling assumptions, such as how the assignment cost function is defined, can case a tracker to make error regardless of how strong the optimization approach is.

##### Greedy Randomized Search
Heuristically searching through the space of valid solutions within a time limit is an attractive way of ensuring both real-time performance and that a good local optima will be discovered. The most weill-known method, the greedy Randomized Adaptive Search Procedure (GRASP), was originally introduced for multi-sensor multi-target tracking. The idea behind GRASP is to randomly select each partial assignment from lists of greedily chosen candidates to form a solution $$\gamma$$. Then a local random search is conducted to attempt to improve this solution. This procedure is repeated until the alloted time runs out or a maximum number of iterations is reached, at which point the best solution that was dicovered is returned. GRASP algorithm also use gating techniques to help reduce the search space, and conduct the local searches by permuting a small number entries within some of the assgnments. 

Other greedy search algorithms have been proposed, based on the semi-greedy track selection (SGTS) algorithm introduced. SGTS-based algorithms first perform the usual greedy assignment algorithm step of sorting potential tracks by track score. Then, they gernate a list of candidate hypotheses and return the local optimal result. This processis repeated iteratively in a manner so that candidate hypotheses are generated that best represent the solution space. The construction of SGTS and its extensions are such that they can provide a solution that is within a guarantted factor of the optimal solution.

The main strength of search algorithm appear to be their simi;icity and the extent to which they are embarrassingly parallel. Despite being quite genral, the advent of more sophisiticated techquies that can leverage problem-specific information and the necessary hardware necessary to run them in real-time has most likely contributed to the lack of continued research on GRASP algorithms in the accademic tracking community.

#### Lagrangian Relaxation
The multidimensional binary constraints pose a significant challenge; a standard technique is to relax the constraints so that a polynomial-time algorithm can be used to find an acceptable sub-optimal solution. The existence of $$O(n^3)$$ algorithms for LAP suggests that if the constraints can be relaxed, a reasonably good solution to the MDAP should be obtainable within an acceptable amount of time. Indeed, Lagrangian relaxation algorithms for association in multi-target tracing, involve iteratively producing increasingly better solutions to the MDAP by successively solving relaxed LAPs and reinforcing the constraints. As set of Lagrange multipliers for the N-dimensional case, $$\mathbb{u} = [u_3, u_4, \cdots, u_N]$$